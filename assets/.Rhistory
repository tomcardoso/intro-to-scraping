View(page)
page
page_node <- page %>%
html_nodes('#wb-main-in > table')
View(page_node)
page_node <- page %>%
html_nodes('#wb-main-in > table') %>%
html_table()
View(page_node)
View(page_node)
as.data.frame(page_node)
page_node <- page %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as_data_frame(.)
page_node <- page %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as_data_frame()
page_node <- page %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame()
View(page_node)
page_table_easy <- page %>%
html_nodes('//*[@id="wb-main-in"]/table') %>%
html_table() %>%
as.data.frame()
page_table_easy <- page %>%
html_nodes(xpath = '//*[@id="wb-main-in"]/table') %>%
# html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame()
View(page_table_easy)
rm(list=ls())
library('tidyverse')
library('rvest')
setwd('~/Sites/personal/intro-to-scraping/assets')
# We'll get back to this URL later if we have time
index_page_url <- 'https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/cl.pl?lang=eng&SCR=Q&Sort=0'
# For now, let's focus on this page
contracts_url <- 'https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/cl.pl?lang=eng;SCR=L;Sort=0;PF=CL201617Q3.txt'
contracts_page <- read_html(contracts_url)
# Let's type `page` into the RStudio console and take a look. rvest has grabbed the HTML!
# Next, let's take a look at the page in Chrome Developer Tools and see if we can extract a selector we can grab
# Selector will look like this: '#wb-main-in > table'
# XPath looks like this: '//*[@id="wb-main-in"]/table'
# First, let's scrape the easy way, using `html_table`. This doesn't always work, especially if your data isn't actually in a table
contracts_table <- contracts_page %>%
html_nodes('#wb-main-in > table') %>%
# html_nodes(xpath = '//*[@id="wb-main-in"]/table') %>%
html_table() %>%
as.data.frame()
contracts_table_parsed <- contracts_table %>%
mutate(date_parsed = as.Date('Contract.Date'))
View(contracts_table)
contracts_table_parsed <- contracts_table %>%
mutate(date_parsed = lubridate::ymd('Contract.Date'))
View(contracts_table_parsed)
contracts_table_parsed <- contracts_table %>%
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(date_parsed = lubridate::ymd(contract_date))
contracts_table_parsed <- contracts_table %>%
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(contract_date = as.Date(contract_date))
View(contracts_table_parsed)
contracts_table_parsed <- contracts_table %>%
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(
contract_date = as.Date(contract_date),
value = parse_number(value)
)
contracts_table_parsed <- contracts_table %>%
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(
contract_date = as.Date(contract_date),
value_no_spaces = str_replace_all(' ', ''),
value = parse_number(value_no_spaces)
)
contracts_table_parsed <- contracts_table %>%
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(
contract_date = as.Date(contract_date),
value_no_spaces = str_replace_all('\\s', ''),
value = parse_number(value_no_spaces)
)
contracts_table_parsed <- contracts_table %>%
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(
contract_date = as.Date(contract_date),
value_no_spaces = str_replace_all('[:space:]', ''),
value = parse_number(value_no_spaces)
)
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(
contract_date = as.Date(contract_date),
value_no_spaces = str_replace_all('[[:space:]]', ''),
value = parse_number(value_no_spaces)
)
contracts_table_parsed <- contracts_table %>%
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(
contract_date = as.Date(contract_date),
value_no_spaces = str_replace_all('[[:space:]]', ''),
value = parse_number(value_no_spaces)
)
contracts_table_parsed <- contracts_table %>%
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(
contract_date = as.Date(contract_date),
value_no_spaces = str_replace_all(value, '\\s', ''),
value = parse_number(value_no_spaces)
)
rm(list=ls())
library('tidyverse')
library('rvest')
setwd('~/Sites/personal/intro-to-scraping/assets')
# We'll get back to this URL later if we have time
index_page_url <- 'https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/cl.pl?lang=eng&SCR=Q&Sort=0'
# For now, let's focus on this page
contracts_url <- 'https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/cl.pl?lang=eng;SCR=L;Sort=0;PF=CL201617Q3.txt'
contracts_page <- read_html(contracts_url)
# Let's type `page` into the RStudio console and take a look. rvest has grabbed the HTML!
# Next, let's take a look at the page in Chrome Developer Tools and see if we can extract a selector we can grab
# Selector will look like this: '#wb-main-in > table'
# XPath looks like this: '//*[@id="wb-main-in"]/table'
# First, let's scrape the easy way, using `html_table`. This won't always work, especially if your data isn't actually in a table, but it's very powerful
contracts_table <- contracts_page %>%
html_nodes('#wb-main-in > table') %>%
# html_nodes(xpath = '//*[@id="wb-main-in"]/table') %>% # you could also write it using XPath this way
html_table() %>%
as.data.frame()
contracts_table_parsed <- contracts_table %>%
rename(
contract_date = 'Contract.Date',
vendor_name = 'Vendor.Name',
description = 'Description.of.Work',
value = 'Contract.Value'
) %>%
mutate(
contract_date = as.Date(contract_date),
value_no_spaces = str_replace_all(value, '\\s', ''),
value = parse_number(value_no_spaces)
)
travel_expenses <- 'https://www.tpsgc-pwgsc.gc.ca/proactive/voyage-travel/dv-th-182-eng.html'
travel_page <- read_html(travel_expenses)
# Now, if we grab the selector for the list items (<li>'s) from Dev Tools, we'll end up with something like this:
# '#wb-main-in > ul:nth-child(4) > li:nth-child(1)'
# Testing that out in the Chrome console reveals that it's only selecting that one list item â€” not what we want!
# Instead, let's rewrite that to be more general:
# '#wb-main-in > ul > li'
# Now we're grabbing *all* list items at once. Let's test it out:
travel_index <- travel_page %>%
html_nodes('#wb-main-in > ul > li')
View(travel_index)
travel_index[1]
travel_index[2]
travel_index[3]
travel_index[4]
travel_index[5]
travel_index[5] %>% html_attr('href')
travel_index[5] %>% html_attr('a:href')
travel_index[5] %>% html_attr('a')
travel_index <- travel_page %>%
html_nodes('#wb-main-in > ul > li a')
travel_index[5]
travel_index[5] %>% html_attr('a')
travel_index[5] %>% html_attr('href')
travel_index[5] %>% html_text('href')
travel_index <- travel_page %>%
html_nodes('#wb-main-in > ul > li > a')
travel_index <- travel_page %>%
html_nodes('#wb-main-in > ul > li > a') %>%
mutate(derp = 'hello')
travel_index <- travel_page %>%
html_nodes('#wb-main-in > ul > li > a') %>%
map(xml_attrs) %>%
map_df(~as.list(.))
View(travel_index)
travel_index <- travel_page %>%
html_nodes('#wb-main-in > ul > li') %>%
map(xml_attrs) %>%
map_df(~as.list(.))
travel_index <- travel_page %>%
html_nodes('#wb-main-in > ul > li > a')
travel_links <- travel_index %>%
html_attr('href')
travel_text <- travel_index %>%
html_text()
travel_index_parsed <- data_frame(link = travel_links, url = travel_text)
View(travel_index_parsed)
travel_index_parsed <- data_frame(text = travel_text, url = travel_links) %>%
mutate(
id = row_number(),
full_url = paste('https://www.tpsgc-pwgsc.gc.ca/', url, sep = '')
)
travel_details <- data_frame(date = NA, purpose = NA, total_cost = NA)
View(travel_details)
travel_details <- data_frame(date, purpose, total_cost)
travel_details <- data_frame(date = c(), purpose = c(), total_cost = c())
travel_details <- data_frame(date = character(), purpose = character(), total_cost = character())
page <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
page <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('wb-main-in > table') %>%
html_table()
View(page)
page <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('wb-main-in > table') %>%
html_table() %>%
as.data.frame()
View(page)
page <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('wb-main-in > table')
View(page)
page <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('wb-main-in > table') %>%
html_table()
View(page)
page
read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('wb-main-in > table') %>%
html_table() %>%
as.data.frame()
read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('wb-main-in > table') %>%
html_table()
page2 <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('wb-main-in > table')
View(page2)
page2 <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372')
View(page2)
page2 <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('#wb-main-in > table > tbody > tr')
View(page2)
View(page2)
page2 <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372')
View(page2)
page2
page2[2]
View(page2)
View(page2)
page2
page2 %>% as.data.frame()
page2 <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('#wb-main-in')
View(page2)
page2
page2$
doc
page2[1]
page2[1][1]
page2[[1]]
page2 <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('#wb-main-in table')
page2 <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('#wb-main-in table') %>%
html_table()
View(page2)
page2 <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('#wb-main-in table') %>%
html_table() %>%
as.data.frame()
View(page2)
page2 <- read_html('https://www.tpsgc-pwgsc.gc.ca/cgi-bin/proactive/th.pl?lang=eng;SCR=L;PF=2018Q2;ID=372') %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame()
View(page2)
travel_index_parsed <- data_frame(text = travel_text, url = travel_links) %>%
mutate(
id = row_number(),
full_url = paste('https://www.tpsgc-pwgsc.gc.ca/', url, sep = '')
)
# Now let's go a step deeper and scrape those pages in turn! First, let's set up an empty dataframe we'll write to
travel_details <- data_frame(date = character(), purpose = character(), total_cost = character())
# And a function we'll run over the data
scrape_inner_page <- function (url) {
browser();
page <- read_html(url) %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame() %>%
rename(
date = 'Date.s.',
purpose = 'Purpose',
total_cost = 'Total.Cost'
) %>%
filter(date !== 'TOTAL')
travel_details <- bind_rows(travel_details, page)
}
travel_index_parsed %>%
map(scrape_inner_page)
travel_index_parsed <- data_frame(text = travel_text, url = travel_links) %>%
mutate(
id = row_number(),
full_url = paste('https://www.tpsgc-pwgsc.gc.ca/', url, sep = '')
)
# Now let's go a step deeper and scrape those pages in turn! First, let's set up an empty dataframe we'll write to
travel_details <- data_frame(date = character(), purpose = character(), total_cost = character())
# And a function we'll run over the data
scrape_inner_page <- function (url) {
browser();
page <- read_html(url) %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame() %>%
rename(
date = 'Date.s.',
purpose = 'Purpose',
total_cost = 'Total.Cost'
) %>%
filter(date != 'TOTAL')
travel_details <- bind_rows(travel_details, page)
}
travel_index_parsed %>%
map(scrape_inner_page)
url
url$
travel_index_parsed %>%
map(scrape_inner_page(url))
travel_index_parsed %>%
split(.$full_url) %>%
map(scrape_inner_page)
url$full_url
travel_details <- data_frame(date = character(), purpose = character(), total_cost = character())
# And a function we'll run over the data
scrape_inner_page <- function (df) {
page <- read_html(df$full_url) %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame() %>%
rename(
date = 'Date.s.',
purpose = 'Purpose',
total_cost = 'Total.Cost'
) %>%
filter(date != 'TOTAL')
travel_details <- bind_rows(travel_details, page)
}
travel_index_parsed %>%
split(.$full_url) %>%
map(scrape_inner_page)
scrape_inner_page <- function (df) {
browser()
page <- read_html(df$full_url) %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame() %>%
rename(
date = 'Date.s.',
purpose = 'Purpose',
total_cost = 'Total.Cost'
) %>%
filter(date != 'TOTAL')
travel_details <- bind_rows(travel_details, page)
}
travel_index_parsed %>%
split(.$full_url) %>%
map(scrape_inner_page)
scrape_inner_page <- function (df) {
page <- read_html(df$full_url) %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame() %>%
rename(
date = 'Date.s.',
purpose = 'Purpose',
total_cost = 'Total.Cost'
) %>%
filter(date != 'TOTAL')
travel_details <- bind_rows(travel_details, page)
}
travel_index_parsed %>%
split(.$full_url) %>%
map(scrape_inner_page)
.
read_html(df$full_url) %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame()
scrape_inner_page <- function (df) {
page <- read_html(df$full_url) %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame()
if (nrow(page) > 0) {
page <- page %>%
rename(
date = 'Date.s.',
purpose = 'Purpose',
total_cost = 'Total.Cost'
) %>%
filter(date != 'TOTAL')
travel_details <- bind_rows(travel_details, page)
}
}
travel_index_parsed %>%
split(.$full_url) %>%
map(scrape_inner_page)
for (i in seq(nrow(travel_index_parsed))) {
browser()
}
i
travel_index_parsed
travel_index_parsed[i]
travel_index_parsed[1, i]
travel_index_parsed[2, i]
travel_index_parsed[i, 1]
travel_index_parsed[i, 3]
travel_index_parsed[i, 4]
travel_index_parsed[i, 3]
exit
quit
brow
scrape_inner_page <- function(url) {
page <- read_html(url) %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame()
if (nrow(page) > 0) {
page <- page %>%
rename(
date = 'Date.s.',
purpose = 'Purpose',
total_cost = 'Total.Cost'
) %>%
filter(date != 'TOTAL')
}
return page
}
# travel_index_parsed %>%
#   split(.$full_url) %>%
#   map(scrape_inner_page)
for (i in seq(nrow(travel_index_parsed))) {
row <- travel_index_parsed[i, 3]
url <- travel_index_parsed[i, 4]
data <- scrape_inner_page(url)
browser()
# travel_details <- bind_rows(travel_details, page)
}
data
scrape_inner_page <- function(url) {
page <- read_html(url) %>%
html_nodes('#wb-main-in > table') %>%
html_table() %>%
as.data.frame()
if (nrow(page) > 0) {
page <- page %>%
rename(
date = 'Date.s.',
purpose = 'Purpose',
total_cost = 'Total.Cost'
) %>%
filter(date != 'TOTAL')
}
return page
}
# travel_index_parsed %>%
#   split(.$full_url) %>%
#   map(scrape_inner_page)
for (i in seq(nrow(travel_index_parsed))) {
row <- travel_index_parsed[i, 3]
url <- travel_index_parsed[i, 4]
data <- scrape_inner_page(url)
# browser()
travel_details <- bind_rows(data, page)
}
